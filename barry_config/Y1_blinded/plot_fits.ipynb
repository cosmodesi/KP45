{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd74ef87-d47b-4434-8197-30e0e515cdde",
   "metadata": {},
   "source": [
    "# Plot Y1 blinded chains\n",
    "This jupyter notebook contains some code to make plots of the bestfits and contours for each of the Y1 blinded samples, looping over each tracer and cap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed58620-7109-4295-8290-60ab05b99780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "from barry.samplers import DynestySampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.utils import weighted_avg_and_cov\n",
    "\n",
    "# Read in the fitter class to get all the info on the fit\n",
    "pfn = \"./plots/run_fits/output/run_fits.fitter.pkl\"\n",
    "with open(pfn, 'rb') as pickle_file:\n",
    "    fitter = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b70228-00e1-4605-96af-6ebbad3b48e1",
   "metadata": {},
   "source": [
    "This code segment reads in the chains, plots the bestfit model vs. data and prepares stuff for contour plots and summary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b016c6a-8047-4c8f-b29c-1b2ef79ce6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "logging.info(\"Creating plots\")\n",
    "\n",
    "c = [ChainConsumer(), ChainConsumer(), ChainConsumer(), ChainConsumer(), ChainConsumer(), ChainConsumer()]\n",
    "\n",
    "# The different tracers and redshift bins\n",
    "tracers = {'BGS_BRIGHT-21.5': [[0.1, 0.4]], \n",
    "           'LRG': [[0.4, 0.6], [0.6, 0.8], [0.8, 1.1]], \n",
    "           'ELG_LOPnotqso': [[0.8, 1.1], [1.1, 1.6]],\n",
    "           'QSO': [[0.8, 2.1]]}\n",
    "\n",
    "# The different sky areas\n",
    "caps = [\"NGC\", \"SGC\", \"GCcomb\"]\n",
    "\n",
    "# Set up some convenient colours\n",
    "cs = [\"#74B666\",\"#38AA88\",\"#2899A0\",\"#5783A4\",\"#7E6990\",\"#8F526C\",\"#894446\"]\n",
    "\n",
    "# Let's group together the three caps so we can overplot them on the same contour plot\n",
    "datanames = [f\"{t}_{zs[0]}_{zs[1]}\" for t in tracers for i, zs in enumerate(tracers[t])]\n",
    "cfull = [ChainConsumer() for d in datanames]\n",
    "csmall = [ChainConsumer() for d in datanames]\n",
    "\n",
    "# Loop over all the chains\n",
    "output = []\n",
    "for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "\n",
    "    # Match the chain to the datanames list created above\n",
    "    subname = extra[\"name\"].split()[3]\n",
    "    tracer = (\"_\").join(subname.split(\"_\")[:-3])\n",
    "    cap, zmin, zmax = subname.split(\"_\")[-3:]\n",
    "    chainname = f\"{tracer}_{zmin}_{zmax}\"\n",
    "    dataname_index = [i for i, n in enumerate(datanames) if chainname in n][0]\n",
    "    \n",
    "    # Store the chain in a dictionary with parameter names\n",
    "    df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "\n",
    "    # Compute alpha_par and alpha_perp for each point in the chain\n",
    "    alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "    df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "    df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "\n",
    "    # Get the MAP point and set the model up at this point\n",
    "    model.set_data(data)\n",
    "    r_s = model.camb.get_data()[\"r_s\"]\n",
    "    max_post = posterior.argmax()\n",
    "    params = df.loc[max_post]\n",
    "    params_dict = model.get_param_dict(chain[max_post])\n",
    "    for name, val in params_dict.items():\n",
    "        model.set_default(name, val)\n",
    "\n",
    "    # Get some useful properties of the fit, and plot the MAP model against the data\n",
    "    #display = True if \"GCcomb\" in extra[\"name\"] else False\n",
    "    figname = f\"./plots/run_fits/{extra['name'].replace(' ', '_')}_bestfit.png\" if \"GCcomb\" in extra[\"name\"] else None\n",
    "    new_chi_squared, dof, bband, mods, smooths = model.simple_plot(params_dict, display=False, figname=figname, c=cs[dataname_index])\n",
    "\n",
    "    # Add the chain to the appropriate ChainConsumer instance\n",
    "    if 'realisation' in extra.keys():\n",
    "        extra.pop('realisation')\n",
    "    cfull[dataname_index].add_chain(df, weights=weight, name=cap, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "    if \"GCcomb\" in extra[\"name\"]:\n",
    "        csmall[dataname_index].add_chain(df, weights=weight, name=cap, plot_contour=True, plot_point=False, show_as_1d_prior=False, color=cs[dataname_index])\n",
    "    \n",
    "    # Compute some summary statistics and add them to a dictionary\n",
    "    mean, cov = weighted_avg_and_cov(\n",
    "        df[\n",
    "            [\n",
    "                \"$\\\\alpha$\",\n",
    "                \"$\\\\epsilon$\",\n",
    "                \"$\\\\alpha_\\\\parallel$\",\n",
    "                \"$\\\\alpha_\\\\perp$\",\n",
    "                \"$\\\\Sigma_{nl,||}$\",\n",
    "                \"$\\\\Sigma_{nl,\\\\perp}$\",\n",
    "            ]\n",
    "        ],\n",
    "        weight,\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    corr = cov[2, 3] / np.sqrt(cov[2, 2] * cov[3, 3])\n",
    "    output.append(\n",
    "        f\"{extra['name'].replace(' ', '_'):s}, {mean[0]:6.4f}, {mean[1]:6.4f}, {mean[2]:6.4f}, {mean[3]:6.4f}, {mean[4]:6.4f}, {mean[5]:6.4f}, {np.sqrt(cov[0, 0]):6.4f}, {np.sqrt(cov[1, 1]):6.4f}, {np.sqrt(cov[2, 2]):6.4f}, {np.sqrt(cov[3, 3]):6.4f}, {corr:7.3f}, {r_s:7.3f}, {new_chi_squared:7.3f}, {dof:4d}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473f4bf-4963-4d1b-89b8-b8781c9e731f",
   "metadata": {},
   "source": [
    "Plot the contour plots and output the summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acbf08fb-9f20-4f41-b598-8b6bdc369fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "truth = {\"$\\\\alpha$\": 1.0, \"$\\\\epsilon$\": 0, \"$\\\\alpha_\\\\perp$\": 1.0, \"$\\\\alpha_\\\\parallel$\": 1.0}\n",
    "for chain_bin in range(len(c)):\n",
    "    print(datanames[chain_bin])\n",
    "    figname = f\"./plots/run_fits/fullchainplot_{datanames[chain_bin]}.png\"\n",
    "    cfull[chain_bin].plotter.plot(\n",
    "        truth=truth,\n",
    "        parameters=[\"$\\\\alpha$\",\"$\\\\epsilon$\",\"$\\\\alpha_\\\\parallel$\", \"$\\\\alpha_\\\\perp$\",\"$\\\\Sigma_{nl,||}$\",\"$\\\\Sigma_{nl,\\\\perp}$\",\"$\\\\Sigma_s$\"],\n",
    "        filename=figname,\n",
    "        figsize=(6,6)\n",
    "    )\n",
    "    \n",
    "    figname = f\"./plots/run_fits/smallchainplot_{datanames[chain_bin]}.png\"\n",
    "    csmall[chain_bin].plotter.plot(\n",
    "        truth=truth,\n",
    "        parameters=[\"$\\\\alpha_\\\\parallel$\", \"$\\\\alpha_\\\\perp$\"],\n",
    "        chains=\"GCcomb\",\n",
    "        filename=figname,\n",
    "        figsize=(6,6)\n",
    "    )\n",
    "    \n",
    "# Save all the numbers to a file\n",
    "with open(\"./plots/run_fits/output/Barry_fits.txt\", \"w\") as f:\n",
    "    f.write(\n",
    "        \"# Name, alpha, epsilon, alpha_par, alpha_perp, Sigma_nl_par, Sigma_nl_perp, sigma_alpha_par, sigma_alpha_perp, corr_alpha_par_perp, rd_of_template, bf_chi2, dof\\n\"\n",
    "    )\n",
    "    for l in output:\n",
    "        f.write(l + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e484e766-155e-44e5-8daa-6f6d63b9d299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmodesi-main",
   "language": "python",
   "name": "cosmodesi-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
