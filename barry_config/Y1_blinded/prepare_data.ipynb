{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82dae1ab-a0c9-4462-aaca-e3c75b3563cd",
   "metadata": {},
   "source": [
    "# Pickle LRG files for Barry\n",
    "This notebook includes code to ingest all the Y1 blinded data files. Barry has a strict set of data inputs, and everything gets pickled up into this format. This means the underlying clustering measurements etc., can be in any format.\n",
    "\n",
    "Barry expects that you will read in/specify and pickle:\n",
    "* The number of correlated datasets. **We set n_data == 1 below, but this would be 2 if we were providing i.e., NGC+SGC data vectors and wanted to consider different bias or polynomials for each cap**\n",
    "* Pre and post-recon data power spectrum with 5 multipoles (some multipoles can be set to zero if they are not required/measured). **Post-recon data currently set to None as it doesn't have the same redshift binning.**\n",
    "* N pre and post-recon mock power spectra with 5 multipoles (some can be set to zero if they are not required/measured). **Mocks currently set to None as we don't have these yet**\n",
    "* Pre and post-recon covariance matrices for the power spectra (some elements/blocks can be set to zero if they are not required/measured). **Pre-recon analytic used for both currently.**\n",
    "* A fiducial cosmology. **I've assumed the DESI fiducial cosmology**\n",
    "* A window function convolution/binning matrix (some elements/blocks can be set to the identify matrix if they are not required/measured), corresponding k-binning and integral constraint. Only needed for power spectra.\n",
    "* A compression matrix to convert the 3 even multipoles to 5 even+odd (can be given as a block identity matrix if you are not measuring odd multipoles). Only needed for power spectra.\n",
    "\n",
    "Correlation functions are similar but a little simpler (only 3 multipoles, and no window function stuff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83fbb50-87dd-4a6a-bd26-c90c7d223fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02237 0.12 0.1206441345126498\n",
      "2.083e-09 0.9649 0.0544\n",
      "0.05999991930682943\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary packages, set up the fiducial cosmology and save the DESI template\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from astropy.io import ascii\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import splrep, splev\n",
    "from cosmoprimo import PowerSpectrumBAOFilter\n",
    "from cosmoprimo.fiducial import DESI\n",
    "from pypower import BaseMatrix, CatalogFFTPower, CatalogFFTCorr, PowerSpectrumMultipoles, PowerSpectrumSmoothWindow, PowerSpectrumSmoothWindowMatrix, PowerSpectrumOddWideAngleMatrix, setup_logging\n",
    "from pycorr import TwoPointCorrelationFunction, project_to_multipoles\n",
    "\n",
    "cosmo = DESI()\n",
    "print(cosmo[\"Omega_b\"]*cosmo[\"h\"]**2, cosmo[\"Omega_cdm\"]*cosmo[\"h\"]**2, cosmo[\"Omega_m\"]*cosmo[\"h\"]**2 - cosmo[\"Omega_b\"]*cosmo[\"h\"]**2)\n",
    "print(cosmo[\"A_s\"], cosmo[\"n_s\"], cosmo[\"tau_reio\"])\n",
    "print(np.sum(cosmo[\"m_ncdm\"]))\n",
    "\n",
    "# Save the default DESI template to a file\n",
    "k_min = 1e-4\n",
    "k_max = 5\n",
    "k_num = 2000\n",
    "kl = np.logspace(np.log(k_min), np.log(k_max), k_num, base=np.e)\n",
    "pkz = cosmo.get_fourier().pk_interpolator()\n",
    "pk = pkz.to_1d(z=0)\n",
    "pkv = pk(kl)\n",
    "pknow = PowerSpectrumBAOFilter(pk, engine='wallish2018').smooth_pk_interpolator()\n",
    "pksmv = pknow(kl)\n",
    "np.savetxt(\"./DESI_Pk_template.dat\", np.c_[kl, pksmv, pkv/pksmv - 1.0],  fmt=\"%g %g %g\", header=\"k     pk_smooth     pk_ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd05d3-4e98-45f8-8dd2-67c65c06bc72",
   "metadata": {},
   "source": [
    "# Correlation function routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bfa8518-6303-45c4-b15e-6dd8f31571d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful utility function to collate some Xi data\n",
    "def collect_xi_data(pre_files, post_files, pre_cov_files, post_cov_files, pre_name, post_name, zs):\n",
    "\n",
    "    pre_data = get_xi(pre_files, pre_name) if pre_files is not None else None\n",
    "    post_data = get_xi(post_files, post_name) if post_files is not None else None\n",
    "    \n",
    "    pre_cov = get_xi_cov(pre_cov_files, pre_name) if pre_cov_files is not None else None\n",
    "    post_cov = get_xi_cov(post_cov_files, post_name) if post_cov_files is not None else None\n",
    "\n",
    "    pre_mocks, post_mocks = None, None\n",
    "\n",
    "    split = {\n",
    "        \"n_data\": 1,\n",
    "        \"pre-recon data\": pre_data,\n",
    "        \"pre-recon cov\": pre_cov,\n",
    "        \"post-recon data\": post_data,\n",
    "        \"post-recon cov\": post_cov,\n",
    "        \"pre-recon mocks\": pre_mocks,\n",
    "        \"post-recon mocks\": post_mocks,\n",
    "        \"cosmology\": {\n",
    "            \"om\": cosmo[\"Omega_m\"],\n",
    "            \"h0\": cosmo[\"h\"],\n",
    "            \"z\": (zs[1]+zs[0])/2.0,\n",
    "            \"ob\": cosmo[\"Omega_b\"],\n",
    "            \"ns\": cosmo[\"n_s\"],\n",
    "            \"mnu\": np.sum(cosmo[\"m_ncdm\"]),\n",
    "            \"reconsmoothscale\": 10,\n",
    "        },\n",
    "        \"name\": \"DESI Y1 BLIND \" + pre_name,\n",
    "    }\n",
    "    \n",
    "    with open(f\"./DESI_Y1_BLIND_\" + pre_name.lower().replace(\" \", \"_\")+\".pkl\", \"wb\") as f:\n",
    "        pickle.dump(split, f)\n",
    "        \n",
    "    return split\n",
    "\n",
    "# Correlation function\n",
    "def get_xi(loc, name):\n",
    "    \n",
    "    nran = \"nran5\" if \"MGrecsym\" in name else \"nran4\" \n",
    "    infile = loc + \"xipoles_\" + name + \"_default_FKP_lin4_njack0_\" + nran + \"_split20.txt\"\n",
    "    \n",
    "    xi = pd.read_csv(infile, comment=\"#\", skiprows=0, delim_whitespace=True, header=None, names=[\"s\", \"savg\",\"xi0\",\"xi2\",\"xi4\"])\n",
    "    xi = xi.drop(xi[xi[\"s\"] < 20.0].index)\n",
    "    \n",
    "    return [xi[[\"s\",\"xi0\",\"xi2\",\"xi4\"]]]\n",
    "\n",
    "# Correlation function covariance matrix.\n",
    "def get_xi_cov(loc, name):\n",
    "\n",
    "    nran = \"nran5\" if \"MGrecsym\" in name else \"nran4\" \n",
    "    infile = loc + \"xi024_\" + name + \"_default_FKP_lin4_s20-200_cov_RascalC_Gaussian.txt\"\n",
    "    \n",
    "    cov = pd.read_csv(infile, comment=\"#\", delim_whitespace=True, header=None).to_numpy()\n",
    "    \n",
    "    #plt.imshow(cov/np.sqrt(np.outer(np.diag(cov), np.diag(cov))))\n",
    "    #plt.show()\n",
    "    \n",
    "    # Check the covariance matrix is invertible\n",
    "    v = np.diag(cov @ np.linalg.inv(cov))\n",
    "    if not np.all(np.isclose(v, 1)):\n",
    "        print(\"ERROR, setting an inappropriate covariance matrix that is almost singular!!!!\")\n",
    "\n",
    "    return cov\n",
    "    \n",
    "# Plot the correlation function, for sanity checking\n",
    "def plot_xi(split, pre=True, post=True):\n",
    "        \n",
    "    if pre:\n",
    "    \n",
    "        color = [\"r\", \"b\", \"g\"]\n",
    "        ss = split[\"pre-recon data\"][0][\"s\"]\n",
    "        label = [r\"$\\xi_{0}(k)$\", r\"$\\xi_{2}(k)$\", r\"$\\xi_{4}(k)$\"]\n",
    "        for m, xi in enumerate([\"xi0\", \"xi2\", \"xi4\"]):\n",
    "            yerr = ss ** 2 * np.sqrt(np.diag(split[\"pre-recon cov\"]))[m * len(ss) : (m + 1) * len(ss)]\n",
    "            plt.errorbar(\n",
    "                ss,\n",
    "                ss ** 2 * split[\"pre-recon data\"][0][xi],\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "        plt.xlabel(r\"$s$\")\n",
    "        plt.ylabel(r\"$s^{2}\\,\\xi(s)$\")\n",
    "        plt.title(split[\"name\"] + \" Prerecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "        \n",
    "    if post:\n",
    "        \n",
    "        color = [\"r\", \"b\", \"g\"]\n",
    "        ss = split[\"post-recon data\"][0][\"s\"]\n",
    "        label = [r\"$\\xi_{0}(k)$\", r\"$\\xi_{2}(k)$\", r\"$\\xi_{4}(k)$\"]\n",
    "        for m, xi in enumerate([\"xi0\", \"xi2\", \"xi4\"]):\n",
    "            yerr = ss ** 2 * np.sqrt(np.diag(split[\"post-recon cov\"]))[m * len(ss) : (m + 1) * len(ss)]\n",
    "            plt.errorbar(\n",
    "                ss,\n",
    "                ss ** 2 * split[\"post-recon data\"][0][xi],\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "        plt.xlabel(r\"$s$\")\n",
    "        plt.ylabel(r\"$s^{2}\\,\\xi(s)$\")\n",
    "        plt.title(split[\"name\"] + \" Postrecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf4ba9-3f4f-4208-9aa1-f62187bc2d77",
   "metadata": {},
   "source": [
    "# Grab all the various datasets!!\n",
    "This will also plot the datasets, but this has been commented out in the GitHub version for  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5860e2d9-2526-49c0-bb58-47452f4537bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a dictionary of all the combinations of dataset that we have and their redshift bins. First array is zmin, second is zmax\n",
    "tracers = {'BGS_BRIGHT-21.5': [[0.1, 0.4]], \n",
    "           'LRG': [[0.4, 0.6], [0.6, 0.8], [0.8, 1.1]], \n",
    "           'ELG_LOPnotqso': [[0.8, 1.1], [1.1, 1.6]],\n",
    "           'QSO': [[0.8, 2.1]]}\n",
    "\n",
    "# The different sky areas\n",
    "caps = [\"NGC\", \"SGC\", \"GCcomb\"]\n",
    "\n",
    "pre_files = \"/global/cfs/cdirs/desi/survey/catalogs/Y1/LSS/iron/LSScats/v0.1/blinded/xi/smu/\"\n",
    "post_files = \"/global/cfs/cdirs/desi/survey/catalogs/Y1/LSS/iron/LSScats/v0.1/blinded/recon_sm10/xi/smu/\"\n",
    "pre_cov_files = \"/global/cfs/cdirs/desi/users/mrash/RascalC/Y1/blinded/v0.1/\"\n",
    "post_cov_files = \"/global/cfs/cdirs/desi/users/mrash/RascalC/Y1/blinded/v0.1/\"\n",
    "\n",
    "# Now loop over each tracer, redshift bin and cap and gather the files. First pre-recon\n",
    "for t in tracers:\n",
    "    for i, zs in enumerate(tracers[t]):\n",
    "        for cap in caps:\n",
    "            \n",
    "            # Correlation Function\n",
    "            pre_name = f\"{t}_{cap}_{zs[0]}_{zs[1]}\"\n",
    "            data = collect_xi_data(pre_files, None, pre_cov_files, None, pre_name, None, zs)\n",
    "            #plot_xi(data, post=False) # Plot the data to check things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ab9ef-b812-4f37-85c0-d19ddaa60e87",
   "metadata": {},
   "source": [
    "# Test we can load the datasets in Barry\n",
    "This loads in the pickle file using the Barry routines, and then plots the data and a default model. Because I've set marg=\"full\", it will automatically find the best-fit polynomial terms too when plotting, but not the BAO parameters. If this works, a full MCMC BAO fit should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c3f8111-7241-4617-8c18-81c5cff12091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "\n",
    "def plot_xi(data):\n",
    "            \n",
    "    color = [\"r\", \"b\", \"g\"]\n",
    "    ss = split[\"pre-recon data\"][0][\"s\"]\n",
    "    label = [r\"$\\xi_{0}(k)$\", r\"$\\xi_{2}(k)$\", r\"$\\xi_{4}(k)$\"]\n",
    "    for m, xi in enumerate([\"xi0\", \"xi2\", \"xi4\"]):\n",
    "        yerr = ss ** 2 * np.sqrt(np.diag(split[\"pre-recon cov\"]))[m * len(ss) : (m + 1) * len(ss)]\n",
    "        plt.errorbar(\n",
    "            ss,\n",
    "            ss ** 2 * split[\"pre-recon data\"][0][xi],\n",
    "            yerr=yerr,\n",
    "            marker=\"o\",\n",
    "            ls=\"None\",\n",
    "            c=color[m],\n",
    "            label=label[m],\n",
    "        )\n",
    "    plt.xlabel(r\"$s$\")\n",
    "    plt.ylabel(r\"$s^{2}\\,\\xi(s)$\")\n",
    "    plt.title(split[\"name\"] + \" Prerecon\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "for t in tracers:\n",
    "    for i, zs in enumerate(tracers[t]):\n",
    "        for cap in caps:\n",
    "            \n",
    "            name = f\"DESI_Y1_BLIND_{t.lower()}_{cap.lower()}_{zs[0]}_{zs[1]}.pkl\"\n",
    "            dataset = CorrelationFunction_DESI_KP4(\n",
    "                recon=None,\n",
    "                fit_poles=[0, 2],\n",
    "                min_dist=52.0,\n",
    "                max_dist=150.0,\n",
    "                realisation='data',\n",
    "                num_mocks=1000,\n",
    "                reduce_cov_factor=1,\n",
    "                datafile=name,\n",
    "                data_location=\"./\",\n",
    "            )\n",
    "            \n",
    "            model = CorrBeutler2017(\n",
    "                recon=dataset.recon,\n",
    "                isotropic=dataset.isotropic,\n",
    "                marg=\"full\",\n",
    "                poly_poles=dataset.fit_poles,\n",
    "                n_poly=4,    # 4 polynomial terms for Xi(s)\n",
    "            )\n",
    "            \n",
    "            model.set_data(dataset.get_data())\n",
    "            #model.plot(model.get_param_dict(model.get_defaults()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d41b5-48fd-4a87-9ddb-178fbed5eae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmodesi-main",
   "language": "python",
   "name": "cosmodesi-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
