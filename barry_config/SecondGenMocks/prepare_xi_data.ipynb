{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82dae1ab-a0c9-4462-aaca-e3c75b3563cd",
   "metadata": {},
   "source": [
    "# Pickle Abacus SecondGen Xi files for Barry\n",
    "This notebook includes code to ingest all the Abacus SecondGen files. See https://desi.lbl.gov/trac/wiki/keyprojects/y1kp3/clusteringproducts for details on the various types of mocks/data\n",
    "\n",
    "Barry has a strict set of data inputs, and everything gets pickled up into this format. This means the underlying clustering measurements etc., can be in any format.\n",
    "\n",
    "Barry expects that you will read in/specify and pickle:\n",
    "* The number of correlated datasets. **We set n_data == 1 below, but this would be 2 if we were providing i.e., NGC+SGC data vectors and wanted to consider different bias or polynomials for each cap**\n",
    "* Pre and post-recon data power spectrum with 5 multipoles (some multipoles can be set to zero if they are not required/measured). **Post-recon data currently set to None as it doesn't have the same redshift binning.**\n",
    "* N pre and post-recon mock power spectra with 5 multipoles (some can be set to zero if they are not required/measured). **Mocks currently set to None as we don't have these yet**\n",
    "* Pre and post-recon covariance matrices for the power spectra (some elements/blocks can be set to zero if they are not required/measured). **Pre-recon analytic used for both currently.**\n",
    "* A fiducial cosmology. **I've assumed the DESI fiducial cosmology**\n",
    "* A window function convolution/binning matrix (some elements/blocks can be set to the identify matrix if they are not required/measured), corresponding k-binning and integral constraint. Only needed for power spectra.\n",
    "* A compression matrix to convert the 3 even multipoles to 5 even+odd (can be given as a block identity matrix if you are not measuring odd multipoles). Only needed for power spectra.\n",
    "\n",
    "Correlation functions are similar but a little simpler (only 3 multipoles, and no window function stuff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83fbb50-87dd-4a6a-bd26-c90c7d223fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages, set up the fiducial cosmology and save the DESI template\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from astropy.io import ascii\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import splrep, splev\n",
    "from cosmoprimo import PowerSpectrumBAOFilter\n",
    "from cosmoprimo.fiducial import DESI, AbacusSummit\n",
    "from pypower import BaseMatrix, CatalogFFTPower, CatalogFFTCorr, PowerSpectrumMultipoles, PowerSpectrumSmoothWindow, PowerSpectrumSmoothWindowMatrix, PowerSpectrumOddWideAngleMatrix, setup_logging\n",
    "from pycorr import TwoPointCorrelationFunction, project_to_multipoles\n",
    "\n",
    "cosmo = DESI()\n",
    "print(cosmo[\"Omega_b\"]*cosmo[\"h\"]**2, cosmo[\"Omega_cdm\"]*cosmo[\"h\"]**2, cosmo[\"Omega_m\"]*cosmo[\"h\"]**2 - cosmo[\"Omega_b\"]*cosmo[\"h\"]**2)\n",
    "print(cosmo[\"A_s\"], cosmo[\"n_s\"], cosmo[\"tau_reio\"])\n",
    "print(np.sum(cosmo[\"m_ncdm\"]))\n",
    "print(cosmo[\"Omega_m\"], cosmo.Omega_m(0.11), cosmo.growth_rate(0.0), cosmo.growth_rate(0.11), cosmo.growth_rate(0.0)*cosmo.sigma8_z(0.0), cosmo.growth_rate(0.11)*cosmo.sigma8_z(0.11))\n",
    "\n",
    "# Save the default DESI template to a file\n",
    "k_min = 1e-4\n",
    "k_max = 5\n",
    "k_num = 2000\n",
    "kl = np.logspace(np.log(k_min), np.log(k_max), k_num, base=np.e)\n",
    "pkz = cosmo.get_fourier().pk_interpolator()\n",
    "pkz0 = pkz.to_1d(z=0)\n",
    "pkv = pkz0(kl)\n",
    "pknow = PowerSpectrumBAOFilter(pkz0, engine='wallish2018').smooth_pk_interpolator()\n",
    "pksmv = pknow(kl)\n",
    "#np.savetxt(\"./DESI_Pk_template.dat\", np.c_[kl, pksmv, pkv/pksmv - 1.0],  fmt=\"%g %g %g\", header=\"k     pk_smooth     pk_ratio\")\n",
    "#np.savetxt(\"./DESI_Pk_z0p00.dat\", np.c_[kl, pkv, pksmv, pkv/pksmv - 1.0],  fmt=\"%g %g %g %g\", header=\"k     pk         pk_smooth     pk_ratio\")\n",
    "\n",
    "#pkz011 = pkz.to_1d(z=0.11)\n",
    "#pkv = pkz011(kl)\n",
    "#pknow = PowerSpectrumBAOFilter(pkz011, engine='wallish2018').smooth_pk_interpolator()\n",
    "#pksmv = pknow(kl)\n",
    "#np.savetxt(\"./DESI_Pk_z0p11.dat\", np.c_[kl, pkv, pksmv, pkv/pksmv - 1.0],  fmt=\"%g %g %g %g\", header=\"k     pk         pk_smooth     pk_ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd05d3-4e98-45f8-8dd2-67c65c06bc72",
   "metadata": {},
   "source": [
    "# Correlation function routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa8518-6303-45c4-b15e-6dd8f31571d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful utility function to collate some Xi data\n",
    "def collect_xi_data(pre_files, post_files, pre_cov_files, post_cov_files, pre_files_name, post_files_name, pre_cov_name, post_cov_name, zs, reconsmooth, mocks, rpcut, imaging):\n",
    "\n",
    "    pre_data, post_data = None, None\n",
    "    \n",
    "    pre_mocks = get_xi2(pre_files, pre_files_name, mocks, rpcut, imaging) if pre_files_name is not None else None\n",
    "    post_mocks = get_xi2(post_files, post_files_name, mocks, rpcut, imaging) if post_files_name is not None else None\n",
    "    \n",
    "    pre_cov = get_xi_cov(pre_cov_files, pre_cov_name, rpcut, imaging) if pre_cov_name is not None else None\n",
    "    post_cov = get_xi_cov(post_cov_files, post_cov_name, rpcut, imaging) if post_cov_name is not None else None\n",
    "    \n",
    "    rp = f\" {imaging} rpcut2.5\" if rpcut else f\" {imaging}\" \n",
    "    \n",
    "    split = {\n",
    "        \"n_data\": 1,\n",
    "        \"pre-recon data\": pre_data,\n",
    "        \"pre-recon cov\": pre_cov,\n",
    "        \"post-recon data\": post_data,\n",
    "        \"post-recon cov\": post_cov,\n",
    "        \"pre-recon mocks\": pre_mocks,\n",
    "        \"post-recon mocks\": post_mocks,\n",
    "        \"cosmology\": {\n",
    "            \"om\": cosmo[\"Omega_m\"],\n",
    "            \"h0\": cosmo[\"h\"],\n",
    "            \"z\": (zs[1]+zs[0])/2.0,\n",
    "            \"ob\": cosmo[\"Omega_b\"],\n",
    "            \"ns\": cosmo[\"n_s\"],\n",
    "            \"mnu\": np.sum(cosmo[\"m_ncdm\"]),\n",
    "            \"reconsmoothscale\": reconsmooth,\n",
    "        },\n",
    "        \"name\": \"DESI SecondGen \" + f\"sm{reconsmooth} \" +  (\"_\").join(pre_files_name.split(\"_\")[1:]) + rp\n",
    "    }\n",
    "    \n",
    "    with open(f\"/global/cfs/cdirs/desi/users/chowlett/barry_inputs/DESI_SecondGen_sm{reconsmooth}_\" + (\"_\").join(pre_files_name.split(\"_\")[1:]).lower() + (\"_\").join(rp.split(\" \")) + \"_xi.pkl\", \"wb\") as f:\n",
    "        pickle.dump(split, f)\n",
    "        \n",
    "    return split\n",
    "\n",
    "# Correlation function\n",
    "def get_xi(loc, name, mocks, rpcut, imaging):\n",
    "    \n",
    "    rp = \"_rpcut2.5\" if rpcut else \"\" \n",
    "    \n",
    "    xis = []\n",
    "    for mock in mocks:\n",
    "        if 'BGS_BRIGHT-21.5' in name and mock == 13:\n",
    "            continue\n",
    "        infile = loc + f\"/mock{mock}/\" + name + f\"_{imaging}_lin4_njack0_nran4_split20{rp}.txt\"\n",
    "\n",
    "        xi = pd.read_csv(infile, comment=\"#\", skiprows=0, delim_whitespace=True, header=None, names=[\"s\", \"savg\",\"xi0\",\"xi2\",\"xi4\"])\n",
    "        xi = xi.drop(xi[xi[\"s\"] < 20.0].index)\n",
    "        xis.append(xi)\n",
    "\n",
    "    return xis\n",
    "\n",
    "def get_xi2(loc, name, rpcut, imaging):\n",
    "    \n",
    "    infile = loc + \"allcounts_\" + name + \".npy\"\n",
    "    \n",
    "    result = TwoPointCorrelationFunction.load(infile)\n",
    "    factor = 4\n",
    "    rebinned = result[:(result.shape[0] // factor) * factor:factor]\n",
    "    sep, xi = rebinned(ells=(0, 2, 4), return_sep=True, return_std=False)\n",
    "\n",
    "    xis = pd.DataFrame({'s': sep, 'xi0': xi[0], 'xi2': xi[1], 'xi4': xi[2]})\n",
    "    xis = xis.drop(xis[xis[\"s\"] < 20.0].index)\n",
    "    \n",
    "    return [xis[[\"s\",\"xi0\",\"xi2\",\"xi4\"]]]\n",
    "\n",
    "# Correlation function covariance matrix.\n",
    "def get_xi_cov(loc, name, rpcut, imaging):\n",
    "\n",
    "    s = \"rescaled\"\n",
    "    infile = loc + \"xi024_\" + name.replace(\"sm30\",\"sm20\") + f\"_{imaging}_lin4_s20-200_cov_RascalC_{s}.txt\"    # No recon_sm30 cov for QSO yet\n",
    "    \n",
    "    cov = pd.read_csv(infile, comment=\"#\", delim_whitespace=True, header=None).to_numpy()\n",
    "    \n",
    "    #plt.imshow(cov/np.sqrt(np.outer(np.diag(cov), np.diag(cov))))\n",
    "    #plt.show()\n",
    "    \n",
    "    # Check the covariance matrix is invertible\n",
    "    v = np.diag(cov @ np.linalg.inv(cov))\n",
    "    if not np.all(np.isclose(v, 1)):\n",
    "        print(\"ERROR, setting an inappropriate covariance matrix that is almost singular!!!!\")\n",
    "\n",
    "    return cov\n",
    "    \n",
    "# Plot the correlation function, for sanity checking\n",
    "def plot_xi(split, pre=True, post=True):\n",
    "\n",
    "    color = [\"r\", \"b\", \"g\"]\n",
    "    ss = split[\"pre-recon mocks\"][0][\"s\"]\n",
    "    nmocks = len(split[\"pre-recon mocks\"])\n",
    "    label = [r\"$\\xi_{0}(k)$\", r\"$\\xi_{2}(k)$\", r\"$\\xi_{4}(k)$\"]\n",
    "    \n",
    "    if pre:\n",
    "        for m, xi in enumerate([\"xi0\", \"xi2\", \"xi4\"]):\n",
    "            yerr = ss ** 2 * np.sqrt(np.diag(split[\"pre-recon cov\"]))[m * len(ss) : (m + 1) * len(ss)]\n",
    "            plt.errorbar(\n",
    "                ss,\n",
    "                ss ** 2 * np.mean([split[\"pre-recon mocks\"][i][xi] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(ss, ss ** 2 * split[\"pre-recon mocks\"][i][xi], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$s$\")\n",
    "        plt.ylabel(r\"$s^{2}\\,\\xi(s)$\")\n",
    "        plt.title(split[\"name\"] + \" Prerecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "    if post:\n",
    "        for m, xi in enumerate([\"xi0\", \"xi2\", \"xi4\"]):\n",
    "            yerr = ss ** 2 * np.sqrt(np.diag(split[\"post-recon cov\"]))[m * len(ss) : (m + 1) * len(ss)]\n",
    "            plt.errorbar(\n",
    "                ss,\n",
    "                ss ** 2 * np.mean([split[\"post-recon mocks\"][i][xi] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(ss, ss ** 2 * split[\"post-recon mocks\"][i][xi], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$s$\")\n",
    "        plt.ylabel(r\"$s^{2}\\,\\xi(s)$\")\n",
    "        plt.title(split[\"name\"] + \" Postrecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf4ba9-3f4f-4208-9aa1-f62187bc2d77",
   "metadata": {},
   "source": [
    "# Grab all the various datasets!!\n",
    "This will also plot the datasets, but this has been commented out in the GitHub version for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860e2d9-2526-49c0-bb58-47452f4537bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The catalogue version\n",
    "version = 1.2\n",
    "ffa = \"ffa\"               # Flavour of fibre assignment. Can be \"ffa\" for fast fiber assign, or \"complete\"\n",
    "rpcut = False             # Whether or not to include the rpcut\n",
    "imaging = \"default_FKP\"   # What form of imaging systematics to use. Can be \"default_FKP\", \"default_FKP_addSN\", or \"default_FKP_addRF\"\n",
    "\n",
    "# This is a dictionary of all the combinations of dataset that we have and their redshift bins.\n",
    "tracers = {'BGS_BRIGHT-21.5': [[0.1,0.4]],\n",
    "           'LRG': [[0.4, 0.6], [0.6, 0.8], [0.8, 1.1]], \n",
    "           'ELG_LOP': [[0.8, 1.1], [1.1, 1.6]],\n",
    "           'QSO': [[0.8, 2.1]]}\n",
    "\n",
    "# How many complete mocks are available for each tracer? \n",
    "# While the mocks are still being processed, this allows us to skip over the missing entries\n",
    "nmocks = {'BGS_BRIGHT-21.5': [0,25], 'LRG': [0,25], 'ELG_LOP': [0,25], 'QSO': [0,25]}\n",
    "\n",
    "# This dictionary specifies the particulars of how reconstruction was run on each tracer. First entry is smoothing scale, second is type of recon. \n",
    "# QSO has no recon, so set to None so it can be skipped over later.\n",
    "recon = {'BGS_BRIGHT-21.5': [15, \"IFTrecsym\"],\n",
    "         'LRG': [10, \"IFTrecsym\"], \n",
    "         'ELG_LOP': [10, \"IFTrecsym\"],\n",
    "         'QSO': [30, \"IFTrecsym\"]}\n",
    "\n",
    "# The different sky areas\n",
    "caps = [\"NGC\", \"SGC\", \"GCcomb\"]\n",
    "\n",
    "basepath = f\"/global/cfs/cdirs/desi/survey/catalogs/Y1/mocks/SecondGenMocks/\"\n",
    "pre_cov_files = f\"/global/cfs/cdirs/desi/users/mrash/RascalC/Y1/unblinded/v{version}/\"     # At the minute GCcomb uses rescaled, but NGC and SGC just no-rescaling as it's not clear to me which to use.\n",
    "post_cov_files = f\"/global/cfs/cdirs/desi/users/mrash/RascalC/Y1/unblinded/v{version}/\"    # At the minute GCcomb uses rescaled, but NGC and SGC just no-rescaling as it's not clear to me which to use.\n",
    "\n",
    "# Now loop over each tracer, redshift bin and cap and gather the files. First pre-recon\n",
    "for t in tracers:\n",
    "    for i, zs in enumerate(tracers[t]):\n",
    "        for cap in caps:\n",
    "                    \n",
    "            pre_files = basepath + \"/AbacusSummitBGS/\" if t == \"BGS_BRIGHT-21.5\" else basepath + \"/AbacusSummit_v4/\"\n",
    "            post_files = basepath + \"/AbacusSummitBGS/desipipe/v1/ffa/baseline_2pt/recon_recsym\" if t == \"BGS_BRIGHT-21.5\" else basepath + \"/AbacusSummit_v4/\"\n",
    "            pre_files += \"/desipipe/v1/ffa/baseline_2pt/xi/smu/\"\n",
    "            post_files += \"/desipipe/v1/ffa/baseline_2pt/recon_recsym/xi/smu/\"\n",
    "            \n",
    "            pre_name = f\"{t}_{cap}_z{zs[0]}-{zs[1]}\"\n",
    "            post_name = f\"{t}_{cap}_z{zs[0]}-{zs[1]}\"\n",
    "            pre_cov_name = f\"{t}_{cap}_{zs[0]}_{zs[1]}\"\n",
    "            post_cov_name = f\"{t}_{recon[t][1]}_sm{recon[t][0]}_{cap}_{zs[0]}_{zs[1]}\"\n",
    "            \n",
    "            print(pre_name, post_name, pre_cov_name, post_cov_name)\n",
    "            \n",
    "            data = collect_xi_data(pre_files, post_files, pre_cov_files, post_cov_files, pre_name, post_name, pre_cov_name, post_cov_name, zs, recon[t][0], range(nmocks[t][0], nmocks[t][1]), rpcut, imaging)\n",
    "            plot_xi(data, post=False if post_name is None else True) # Plot the data to check things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e51aa4-008c-4898-ac79-aa005afc3637",
   "metadata": {},
   "source": [
    "# Test we can load the datasets in Barry\n",
    "This loads in the pickle file using the Barry routines, and then plots the data and a default model. Because I've set marg=\"full\", it will automatically find the best-fit polynomial terms too when plotting, but not the BAO parameters. If this works, a full MCMC BAO fit should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3f8111-7241-4617-8c18-81c5cff12091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "\n",
    "for t in tracers:\n",
    "    for i, zs in enumerate(tracers[t]):\n",
    "        for cap in caps:\n",
    "            rec = [None] if t == \"QSO\" else [None, \"sym\"]\n",
    "            for r in rec:\n",
    "            \n",
    "                rp = f\"{imaging}_rpcut2.5\" if rpcut else f\"{imaging}\"\n",
    "                name = f\"DESI_SecondGen_sm{recon[t][0]}_{t.lower()}_{ffa}_{cap.lower()}_{zs[0]}_{zs[1]}_{rp}_xi.pkl\"\n",
    "                dataset = CorrelationFunction_DESI_KP4(\n",
    "                    recon=r,\n",
    "                    fit_poles=[0, 2],\n",
    "                    min_dist=52.0,\n",
    "                    max_dist=150.0,\n",
    "                    realisation=0,\n",
    "                    num_mocks=1000,\n",
    "                    reduce_cov_factor=1,\n",
    "                    datafile=name,\n",
    "                    data_location=\"./\",\n",
    "                )\n",
    "\n",
    "                model = CorrBeutler2017(\n",
    "                    recon=dataset.recon,\n",
    "                    isotropic=dataset.isotropic,\n",
    "                    marg=\"full\",\n",
    "                    poly_poles=dataset.fit_poles,\n",
    "                    n_poly=[-2,0,2],    # 4 polynomial terms for Xi(s)\n",
    "                )\n",
    "\n",
    "                model.set_data(dataset.get_data())\n",
    "                print(f\"{dataset.name} Worked!\")\n",
    "                #model.simple_plot(model.get_param_dict(model.get_defaults()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d41b5-48fd-4a87-9ddb-178fbed5eae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmodesi-main",
   "language": "python",
   "name": "cosmodesi-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
